【 每日一问 20190219 bias和variance是什么？如何根据bias和variance对模型进行分析和改善 】
一、偏差（bias）和方差（variance）的含义
（1）泛化误差可以分解成偏差的平方加上方差加上噪声。偏差度量了学习算法的期望预测和真实结果的偏离程度,刻画了学习算法本身的拟合能力,方差度量了同样大小的训练集的变动所导致的学习性能的变化,刻画了数据扰动所造成的影响,噪声表达了当前任务上任何学习算法所能达到的期望泛化误差下界,刻画了问题本身的难度；
（2）偏差和方差一般称为bias和variance,一般训练程度越强,偏差越小,方差越大,泛化误差一般在中间有一个最小值,如果偏差较大,方差较小,此时一般称为欠拟合,而偏差较小,方差较大称为过拟合； 
（3）偏差（bias）和方差（variance）的常见解释: 
解释1
bias 偏差 ：模型的期望（或平均）预测和正确值之间的差别；
variance 方差 ：模型之间的多个拟合预测之间的偏离程度。
解释2：
Bias和Variance分别从两个方面来描述了我们学习到的模型与真实模型之间的差距；
Bias是 “用所有可能的训练数据集训练出的所有模型的输出的平均值” 与 “真实模型”的输出值之间的差异；
Variance则是“不同的训练数据集训练出的模型”的输出值之间的差异。
解释3：
首先 Error = Bias + Variance
Error反映的是整个模型的准确度，Bias反映的是模型在样本上的输出与真实值之间的误差，即模型本身的精准度，Variance反映的是模型每一次输出结果与模型输出期望之间的误差，即模型的稳定性；
更准确地讲Error分成3个部分：Error = Bias + Variance + Noise
（4）解决bias和variance问题的方法：High bias解决方案:Boosting、复杂模型(非线性模型、增加神经网络中的层)、更多特征 ；
High variance解决方案:Bagging、简化模型、降维。
二、如何根据偏差bias和方差variance对模型进行分析和改善
1、理想情况下，我们希望得到一个偏差和方差都很小的模型，但实际上往往很困难；
2、模型评估方法
（1）留出法Hold-out
（2）交叉验证法Cross-validation
（3）自助法Bootstrapping
（4）调参与最终模型
3、性能度量
（1）错误率与精度
（2）查准率、查全率与F1-Score
（3）ROC与AUC
4、通过实验估计学习算法的泛化性能，同时也可以通过“偏差-方差分解”来解释学习算法的泛化性能；
偏差度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力;方差度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响;噪声则表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度；
5、“偏差-方差分解”说明，泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度所共同决定的。给定学习任务，为了取得好的泛化性能，则需使偏差较小，即能够充分拟合数据，并且使方差较小，即使得数据扰动产生的影响小；
6、一般来说，偏差与方差是有冲突的，这称为偏差-方差窘境。假定我们能控制学习算法的训练程度，则在训练不足时，学习器的拟合能力不够强，训练数据的扰动不足以便学习器产生显著变化，此时偏差主导了泛化错误率;随着训练程度的加深，学习器的拟合能力逐渐增强，训练数据发生的扰动渐渐能被学习器学到，方差逐渐主导了泛化错误率;在训练程度充足后，学习器的拟合能力已非常强，训练数据发生的轻微扰动都会导致学习器发生显著变化，若训练数据自身的、非全局的特性被学习器学到了，则将发生过拟合。

三、参考链接
1、https://www.jianshu.com/p/8c7f033be58a
【 每日一问 20190217 Sklearn的常用包有哪些，有什么作用？请分享一下学习的建议和相关资料。】
补充
一、Sklearn常用包
1、Numpy（数值运算库）
2、Scipy（科学计算库）
3、Matplotlib（基础可视化库）
4、Pandas（数据处理库）
5、Seaborn（高级可视化库）
6、Scikit-learn（流行的机器学习库）
二、各自作用
1、Numpy是最为流行的机器学习和数据科学包，Numpy包支持在多维数据上的数学运算，提供数字支持以及相应高效的处理函数，很多更高级的扩展库（包括Scipy、Matplotlib、Pandas等库都依赖于Numpy库）；
2、Scipy包用于科学计算，提供矩阵支持，以及矩阵相关的数值计算模块，其功能包含有最优化、线性代数、积分、插值、拟合、信号处理和图像处理以及其他科学工程中常用的计算；
3、Pandas用于管理数据集，强大、灵活的数据分析和探索工具，其带有丰富的数据处理函数，支持序列分析功能，支持灵活处理缺失数据等；
Pandas基本的数据结构是Series和DataFrame；
Series就是序列，类似一维数组；
DataFrame相当于一张二维的表格，类似二维数组，它的每一列都是一个Series；
为了定位Series中的元素，Pandas提供了Index对象，每个Series都会带有一个对应的Index，用来标记不用的元素；
DataFrame相当于多个带有同样Index的Series的组合（本质是Series的容器）；
4、Matplotlib库用于数据可视化，强大的数据可视化工具以及作图库，其主要用于二维绘图，也可以进行简单的三维绘图；
5、Seaborn库是基于Matplotlib的高级可视化库；
6、Sklearn库包含大量机器学习算法的实现，其提供了完善的机器学习工具箱，支持预处理、回归、分类、聚类、降维、预测和模型分析等强大的机器学习库，近乎一半的机器学习和数据科学项目使用该包。
三、学习建议
Scikit-learn（https://scikit-learn.org/stable/）是一款通用的机器学习库，其中已经包含了许多现成的机器学习模型，以及数据预处理和特征工程，可以很方便地实现常见的机器学习算法，该方式简单方便；为了进一步提高自己对机器学习算法的认知，也可以进一步通过手动实现的方式，对以上的经典算法进行复现（可参考Machine Learning In Action）；同时结合具体的案例，可以更好地掌握机器学习的相关知识点。
四、相关资料与参考链接
1、Machine Learning In Action
2、The State of the Octoverse: machine learning (https://github.blog/2019-01-24-the-state-of-the-octoverse-machine-learning/)

GitHub中较为流行的机器学习和数据科学包



GitHub中较受欢迎的机器学习项目


【 每日一问集锦 20190216 Sat. 一、如何去实践一个完整的
数据挖掘项目 
1、机器学习项目
（1）抽象成数学问题（明确问题）；（2）获取数据；
（3）特征预处理与特征选择；
（4）训练模型与调优；
（5）模型诊断；
（6）模型融合（非必须）；
（8）上线运行。
大部分机器学习项目死在第1步和第2步；平时我们说的机器学习，指的是3、4、5这3步；实践中，其实最难的是“业务理解”这一步，业务理解准备充分了，后面的一切都有章可循。
2、NLP项目
（1）获取语料
已有语料：业务部门、公司积累大量的文本数据；
网上下载、抓取语料：可以通过爬虫自己去抓取一些数据，然后进行加工；
（2）语料预处理
语料预处理大概会占到整个50%-70%的工作量，通过数据洗清、分词、词性标注、去停用词四个大的方面来完成语料的预处理工作。
四大方面
（1）语料清洗：就是在语料中找到我们感兴趣的东西，把不感兴趣的视为噪音的内容清洗删除，如：对于爬取的网页内容，需要去除广告、标签、HTML、JS等代码和注解等；
（2）分词：中文语料数据为一批短文本或长文本，如：句子、文章摘要、段落或整篇文章组成的一个集合。一般句子、段落之间的字、词语是连续的，有一定含义；
（3）词性标注：就是给每个词或者词语打词类标签，如形容词、动词、名词等。这样做可以让文本在后面的处理中融入更多有用的语言信息。如，常见的文本分类就不用关心词性问题，但是类似情感分析、知识推理却是需要的；
（4）去停用词：停用词一般指对文本特征没有任何贡献作用的字词，比如标点符号、语气、人称等一些词。所以在一般性的文本处理中，分词之后，接下来一步就是去停用词。但是比如在情感分析中，语气词、感叹号是应该保留的，因为他们对表示语气程度、感情色彩有一定的贡献和意义。
3、特征工程
（1）做完语料预处理之后，接下来需要考虑如何把分词之后的字和词语表示成计算机能够计算的类型。把中文分词的字符串转换成数字，有两种常用的表示模型分别是词袋模型和词向量；
（2）词袋模型（Bag of Word, BOW)，即不考虑词语原本在句子中的顺序，统计词频这只是最基本的方式，TF-IDF 是词袋模型的一个经典用法；
（3）词向量是将字、词语转换成向量矩阵的计算模型。目前为止最常用的词表示方法是 One-hot，这种方法把每个词表示为一个很长的向量。这个向量的维度是词表大小，其中绝大多数元素为 0，只有一个维度的值为 1，这个维度就代表了当前的词。还有 Google 团队的 Word2Vec，其主要包含两个模型：跳字模型（Skip-Gram）和连续词袋模型（Continuous Bag of Words，简称 CBOW），Word2Vec 词向量可以较好地表达不同词之间的相似和类比关系。除此之外，还有一些词向量的表示方式，如 Doc2Vec、WordRank 和 FastText 等。
4、特征选择
（1）构造好的特征向量，是要选择合适的、表达能力强的特征。文本特征一般都是词语，具有语义信息，使用特征选择能够找出一个特征子集，其仍然可以保留语义信息；
（2）但通过特征提取找到的特征子空间，将会丢失部分语义信息。所以特征选择是一个很有挑战的过程，更多的依赖于经验和专业知识，并且有很多现成的算法来进行特征的选择
6、模型训练
（1）在特征向量选择好之后，接下来就是训练模型，对于不同的应用需求，我们使用不同的模型，传统的有监督和无监督等机器学习模型， 如 kNN、SVM、Naive Bayes、决策树、GBDT、k-Means 等模型；
（2）深度学习模型比如 CNN、RNN、LSTM、 Seq2Seq、FastText、TextCNN 等。这些模型在分类、聚类、神经序列、情感分析等主题中都会用到；
在模型训练时需要注意的几个点：
注意过拟合、欠拟合问题，不断提高模型的泛化能力；
对于神经网络，注意梯度消失和梯度爆炸问题。
7、评价指标
训练好的模型，上线之前要对模型进行必要的评估，目的让模型对语料具备较好的泛化能力。具体有以下这些指标可以参考。（错误率、精度、准确率、精确度、召回率、F1 衡量。）
错误率Error：是分类错误的样本数占样本总数的比例；
精确度Accuracy：是分类正确的样本数占样本总数的比例；
准确率Predict：是针对我们预测结果而言的，它表示的是预测为正的样例中有多少是真正的正样例；
召回率Recall：是针对我们原来的样本而言的，它表示的是样本中的正例有多少被预测正确。
F1 衡量F1-Score：表达出对查准率/查全率的不同偏好；
AUC：
ROC：
8、模型上线应用
模型线上应用，线下训练模型，然后将模型做线上部署，发布成接口服务以供业务系统使用。
二、经典算法梳理之kNN
1、k近邻算法
如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。
2、算法过程
（1）计算测试样本与每个训练样本距离；
（2）排序并选择前k个训练样本；
（3）确定前k个训练样本中各个类别的出现频率，并返回频率最高的分类作为预测分类（出现频率相同的情况如何处理）。
3、优点
（1）理论成熟，思想简单，既可以用来做分类又可以做回归；
（2）可以用于非线性分类；
（3）训练时间复杂度比支持向量机之类的算法要低；
（4）与朴素贝叶斯之类的算法比，对数据没有假设，准确度高，对异常点不敏感；
（5）由于kNN方法主要靠周围有限的邻近的样本，而不是靠判别类域的方法来确定所属的类别，因此对于类域的交叉或重叠较多的待分类样本集来说，kNN方法较其他方法更为适合；（6）该算法比较适用于样本容量比较大的类域的自动分类，而那些样本容量比较小的类域采用这种算法比较容易产生误分类情况。
4、缺点
（1）计算量大，尤其是特征数非常多的时候；
（2）样本不平衡的时候，对稀有类别的预测准确率低；
（3）KD树，球树之类的模型建立需要大量的内存；
（4）是惰性学习方法，基本上不学习，导致预测时速度比起逻辑回归之类的算法慢；
（5）相比决策树模型，kNN模型的可解释性不强。
5、经验
（1）k值设定为多大？
 k太小，分类结果易受噪声点影响；
k太大，近邻中又可能包含太多的其它类别的点。（对距离加权，可以降低k值设定的影响）；
k值通常是采用交叉检验来确定（以k=1为基准）；
经验规则：k一般低于训练样本数的平方根。
（2） 类别如何判定最合适？
投票法没有考虑近邻的距离的远近，距离更近的近邻也许更应该决定最终的分类，所以加权投票法更恰当一些。
（3）如何选择合适的距离衡量？
高维度对距离衡量的影响：
众所周知当变量数越多，欧式距离的区分能力就越差；
 变量值域对距离的影响：值域越大的变量常常会在距离计算中占据主导作用，因此应先对变量进行标准化。
（4） 训练样本是否要一视同仁？
在训练集中，有些样本可能是更值得依赖的；
可以给不同的样本施加不同的权重，加强依赖样本的权重，降低不可信赖样本的影响。
（5）性能问题？
kNN是一种懒惰算法，平时不好好学习，考试（对测试样本分类）时才临阵磨枪（临时去找k个近邻）；
懒惰的后果：构造模型很简单，但在对测试样本分类地的系统开销大，因为要扫描全部训练样本并计算距离；
已经有一些方法提高计算的效率，例如压缩训练样本量等。
（6）能否大幅减少训练样本量，同时又保持分类精度？
浓缩技术(condensing)
编辑技术(editing)
三、Python基础解析之list、tuple
1、概念解释
（1）list
list是一种有序的集合，可以随时添加和删除其中的元素；
用len()函数可以获得list元素的个数；
还可以用-1做索引，直接获取最后一个元素, 以此类推，可以获取倒数第2个(-2)、倒数第3个(-3)；
支持append、insert、pop、push等方法。
（2）tuple
tuple和list非常类似，但是tuple一旦初始化就不能修改，因此，没有append()，insert()这样的方法；
只有1个元素的tuple定义时必须加一个逗号“,”，来消除歧义；
可以正常地使用classmates[0]，classmates[-1]，但不能赋值成另外的元素。
2、相同点与不同点
（1）相同点
元组tuple与列表list都是序列类型的容器对象，可以存放任何类型的数据、支持切片、迭代等操作。
（2）不同点
不可变与可变：两种类型除了字面上的区别(括号与方括号)之外，最重要的一点是【tuple是不可变类型】，大小固定，而 【list 是可变类型】、数据可以动态变化，这种差异使得两者提供的方法、应用场景、性能上都有很大的区别；
同样大小的数据，tuple 占用的内存空间更少；
tuple 对象还可作为字典的键；
列表一般用于存储同构数据，同构数据就是具有相同意义的数据。元组主要用于异构数据，数据库操作中查询出来的记录就是由元组构成的列表结构。
3、具体解释
（1）Python当时的创造者提到过要将元组看作是简单对象的组合，而把列表看作是随时间改变的数据结构；
（2）元组的不可变性提供了某种完整性，确保程序中不会被其他引用所修改；
（3）元组可以用到一些列表无法使用的地方，比如元组可以作为字典键来表示稀疏矩阵。一般来说，列表是对有时需要修改的定序集合工具，而其他需要处理固定关系的情况需要用元组。
【 每日一问 20190215 什么是线性分类器和非线性分类器，有什么区别和优劣？】
1、线性分类器
（1）模型是参数的线性函数，存在线性分类平面，同时分类平面可以是超平面；
（2）二维平面上的两个样本用一条直线分类，三维空间内的两个样本用一个平面分类，N维空间内的两个样本用一个超平面分类；
（3）常见的线性分类器有线性回归、单层感知机、逻辑回归（比较基础的线性分类模型）、SVM（限于线性核函数）、LDA（线性判别分类器）、贝叶斯分类（基于概率思想的简单有效的分类模型，能够给出容易理解的概率解释）。
2、非线性分类器
（1）模型的分界面可以是曲面或者超平面的组合；
（2）二维平面上的两组样本用一条曲线分类，三维空间内的两组样本用一个曲面分类，N维空间内的两组样本用一个超曲面分类；
（2）常见的非线性分类器有kNN、SVM（非线性核函数）、决策树（基于“分类讨论，逐步细化”思想的分类模型，模型直观，易于解释）、RF（随机森林思想与决策树类似，精度通常比决策树要高，缺点是由于随机性，丧失了决策树的可解释性）、GBDT、多层感知机；
SVM（支持向量机）是一个强大的模型，可以用来回归、预测、分类等，根据选取不用的核函数，其模型可以是线性或非线性的。
3、优缺点
（1）线性分类器
算法简单，编程容易，学习速度快，但拟合能力较弱；
（2）非线性分类器
编程复杂，但拟合能力较强。
【 20190214 每日一问 你入门机器学习/深度学习的方式是什么？】
1、方法：
（1）结合吴恩达机器学习视频和课件，边学习、边推导、再编程复现；（2）主要关注点是经典机器学习和数据挖掘经典算法；
（3）每周精读2～3篇自己研究方向的论文，对于存在的难点和迷惑点，主动查阅资料和团队之间交流探讨，针对提出的问题进行分析，以解决问题为目标，同时做好总结和笔录。
2、学习资料
（1）CS229 机器学习（CS229的课程主页为：
http://cs229.stanford.edu/），
作者 Shervine Amidi 关于 CS229 整理了一份超级详细的资源网站，网址为：
https://stanford.edu/~shervine/teaching/cs-229/
（2）Tensorflow实战Google深度学习框架；
（3）利用Scikit-Learning第三方库实现常用算法，理解各算法之间的优缺点和优化手段；
（3）李航统计学习（统计学习是基础）。
3、遇到的问题：
不能很好的把现实中遇到的实际问题转化为易于处理的机器学习或深度学习模型（包括现在比较火的文本分类、图像分类、机器翻译、目标检测、图像超分辨等），主要原因是自己的基础不够扎实，算法和理论方面有所欠缺，对于以上存在的问题，只有自己在平时训练中，多动手、多编程、多实践，才能更好地提高自己的学习效率！

线性回归：适用于自变量与因变量是线性关系；对一个或多个自变量和因变量之间的线性关系进行建模，可用最小二乘法求解模型系数。
逻辑回归：适用于因变量一般有1和0两种取值；是广义线性回归模型的特例，利用逻辑函数将因变量的取值范围控制在0和1之间，表示取值为1的概率。
归纳：常用的回归模型除线性回归、逻辑回归，还有非线性回归、岭回归和主成分回归等。
【20190212每日一问】来自BAT机器学习面试1000题
--------------------------------------------------
在k-means或kNN，我们是用欧氏距离来计算最近的邻居之间的距离。为什么不用曼哈顿距离？
--------------------------------------------------
（1）欧式距离（也称欧几里德度量）用于任何空间的距离计算，没有维度的限制。
（2）曼哈顿距离（L1距离或城市区块距离）有维度的限制，只能计算水平或者垂直方向的距离。
（3）在实际问题求解中，数据点可以任何空间的形式存在，两者相比较而言，欧式距离更适合计算最近邻间的距离。
k-Means/kNN原理、优缺点及其优化
k-Means
优点：
（1）算法快速、简单。
（2）容易解释。
（3）适用于高维。
缺点：
（1）对离群点敏感（包括噪声点和孤立点）。
（2）k的初始化。
（3）聚类中心的选择不同，可能导致完全不同的聚类效果。
【20190213树模型是否需要做归一化等预处理操作？】
1、标准化z-score
公式：(x - mean) / std
作用：将特征转化为均值为0，方差为1的数据。
2、最小最大规范化
公式：(x - min) / (max - min)
作用：将数据转化为[0, 1]区间。
3、概率模型
树模型不需要做归一化处理，因为此类模型不关心变量的值，只关心变量分布和变量之间的条件概率。比如：决策树、随机森林，但Adaboost、Gbdt、Xgboost、SVM、Linear Regression、kNN、kMeans之类的最优化问题是需要做归一化处理的。
4、归一化
基于参数或者距离的模型都需要进行归一化处理，通过L1-norm或L2-norm将数值映射到[0, 1]区间。归一化化就是要把你需要处理的数据经过处理后限制在你需要的一定范围内。 
（1）归一化后加快了梯度下降求最优解的速度，在梯度下降进行求解时能较快的收敛。如果不做归一化,梯度下降过程容易出现锯齿状,很难收敛甚至不能收敛。
（2）把有量纲表达式变为无量纲表达式, 有可能提高精度。一些分类器需要计算样本之间的距离(如欧氏距离),例如kNN,k-Means。如果一个特征值域范围非常大,那么距离计算就主要取决于这个特征,从而与实际情况背道而驰。
5、标准化（Standardization）和归一化（Normalization）的区别
（1）标准化是依据特征矩阵的列处理数据，通过求其z-score的方法，将样本的特征值转换到同一量纲；
（2）归一化是依据特征矩阵的行处理数据，其目的在于样本向量做点乘运算，有统一的标准。
【 20190212 每日一问 在分类问题中,我们经常会遇到正负样本数据量不等的情况,比如正样本为10w条数据,负样本只有1w条数据。对于样本不均衡问题，怎么处理？】
不平衡问题
1、Learning from Imbalanced Data
2、采样方法
a.负样本压缩；
b.正样本提升；
c.Cluster聚类操作；
d.合成数据SMOTE以及阈值调整方法；
e.集成算法；
f.重采样和欠采样；
g.调整权值
3、https://github.com/magicyang5000/Datawhale-Algorithm-Principle/blob/master/Clases_Imbalance_Problem.md
4、

【20190211 每日一问 简要说明一个完整机器学习项目的实践流程】
跨行业数据挖掘标准流程

大致步骤：
1、业务理解（实践中该过程难度较大，也是底层核心）
项目解读：理解题意是第一步，然后进行简单的问题分析，再抽象为数学问题。
2、数据理解
获取数据：并进行数据分析和预处理，对数据划分和打标签。
3、数据准备（费时最多，占比60-70%）
特征提取和特征选择：提取基础特征，进行模型预测。
特征工程
4、建立模型
训练模型：模型优化和模型融合
5、模型评估
6、模型部署（非必需）
上线运行
实践流程：
1、抽象成数学问题（明确问题）
2、获取数据
3、特征预处理和特征选择
4、训练模型与调优
5、模型诊断
6、模型融合（非必需）
7、上线运行
NLP
文本分类深度学习四部曲：
1、词向量
词向量表将高维的稀疏二值向量映射成低维的稠密向量。举个例子，假设我们收到的文本是一串ASCII字符，共有256种可能值，于是我们把每一种可能值表示为一个256维的二值向量。字符’a’的向量只有在第97维的值等于1，其它维度的值都等于0。字符’b’的向量只有在第98维的值等于1，其它维度的值都等于0。这种表示方法称为’one hot’形式。不同字符的向量表示完全不一样。大部分神经网络模型首先都会把输入文本切分成若干个词语，然后将词语都用词向量表示。另一些模型用其它信息扩展了词向量表示。比如，除了词语的ID之外，还会输入一串标签。然后可以学习得到标签向量，将标签向量拼接为词向量。这可以让你将一些位置敏感的信息加入到词向量表示中。然而，有一个更强大的方式来使词语表示呈现出语境相关。
2、编码
假设得到了词向量的序列，编码这一步是将其转化为句子矩阵，矩阵的每一行表示每个词在上下文中所表达的意思。这一步用到了双向RNN模型。LSTM和GRU结构的模型效果都不错。每一行向量通过两部分计算得到：第一部分是正向计算，第二部分是逆向计算，然后拼接两部分得到完整的向量。RNN的主要应用是读入文本内容，然后从中预测出一些信息。而我们是用它来计算一个中间表达状态。最重要的一点是得到的表达能够反映词语在文中的意义。理论上应该学到“pick up”与“pick on”这两个词语的意义有区别。这一直是NLP模型的巨大弱点。现在我们有了一个解决方案。                                           3、注意力机制                                                                                                 这一步是将上一步的矩阵表示压缩为一个向量表示，因此可以被送入标准的前馈神经网络进行预测。注意力机制对于其它压缩方法的优势在于它输入一个辅助的上下文向量。
4、预测                                                                                           
文本内容被压缩成一个向量之后，我们可以学习最终的目标表达 —— 一种类别标签、一个实数值或是一个向量等等。我们也可以将网络模型看做是状态机的控制器，如一个基于转移的解析器，来做结构化预测。   
细粒度情感分析                                                                                    
1、问题理解与建模
对一段UGC的真实评论进行20个细粒度的情感分析，建模为20分类的问题（典型多分类问题）。
2、数据预处理与数据增强
由于停用词去除的实际效果不好，主要进行分词，词性标注。引入大量外部语料，对于elmo这样词表示技术很有提高。数据增强主要在于对训练数据的过采样。
3、词向量预训练
传统word2vec的训练很简单快速，但是这是静态词向量，同一个词在不同的上下文的向量表示完全一样，无法建模词的多义性。所以此处引入elmo动态词向量。
4、模型建模
主要采用端到端的深度学习框架，把20个分类的任务建模为一个多任务学习的框架，好处在于共享网络结构与参数，同时输出20个细粒度分类的结果。
5、结果评估与后处理
在得到NN输出的结果之后，由于训练样本的分布不均衡，通过微调稀有类别的概率阈值，提升整体的评估指标。
NLP大致流程：
1、获取语料
已有语料：业务部门、公司积累大量的文本数据
网上下载、抓取语料：可以通过爬虫自己去抓取一些数据，然后进行加工。
2、语料预处理（语料清洗、分词、词性标注、去停用词）
语料预处理大概会占到整个50%-70%的工作量，通过数据洗清、分词、词性标注、去停用词四个大的方面来完成语料的预处理工作。
a.语料清洗：就是在语料中找到我们感兴趣的东西，把不感兴趣的视为噪音的内容清洗删除，如：对于爬取的网页内容，需要去除广告、标签、HTML、JS等代码和注解等。
b.分词：中文语料数据为一批短文本或长文本，如：句子、文章摘要、段落或整篇文章组成的一个集合。一般句子、段落之间的字、词语是连续的，有一定含义。
c.词性标注：就是给每个词或者词语打词类标签，如形容词、动词、名词等。这样做可以让文本在后面的处理中融入更多有用的语言信息。如，常见的文本分类就不用关心词性问题，但是类似情感分析、知识推理却是需要的。
d.去停用词：停用词一般指对文本特征没有任何贡献作用的字词，比如标点符号、语气、人称等一些词。所以在一般性的文本处理中，分词之后，接下来一步就是去停用词。但是比如在情感分析中，语气词、感叹号是应该保留的，因为他们对表示语气程度、感情色彩有一定的贡献和意义。
3、特征工程 
做完语料预处理之后，接下来需要考虑如何把分词之后的字和词语表示成计算机能够计算的类型。把中文分词的字符串转换成数字，有两种常用的表示模型分别是词袋模型和词向量。
a.词袋模型（Bag of Word, BOW)，即不考虑词语原本在句子中的顺序，统计词频这只是最基本的方式，TF-IDF 是词袋模型的一个经典用法。
b.词向量是将字、词语转换成向量矩阵的计算模型。目前为止最常用的词表示方法是 One-hot，这种方法把每个词表示为一个很长的向量。这个向量的维度是词表大小，其中绝大多数元素为 0，只有一个维度的值为 1，这个维度就代表了当前的词。还有 Google 团队的 Word2Vec，其主要包含两个模型：跳字模型（Skip-Gram）和连续词袋模型（Continuous Bag of Words，简称 CBOW），Word2Vec 词向量可以较好地表达不同词之间的相似和类比关系。除此之外，还有一些词向量的表示方式，如 Doc2Vec、WordRank 和 FastText 等。
4、特征选择
构造好的特征向量，是要选择合适的、表达能力强的特征。文本特征一般都是词语，具有语义信息，使用特征选择能够找出一个特征子集，其仍然可以保留语义信息；但通过特征提取找到的特征子空间，将会丢失部分语义信息。所以特征选择是一个很有挑战的过程，更多的依赖于经验和专业知识，并且有很多现成的算法来进行特征的选择。
5、模型训练 
在特征向量选择好之后，接下来就是训练模型，对于不同的应用需求，我们使用不同的模型，传统的有监督和无监督等机器学习模型， 如 KNN、SVM、Naive Bayes、决策树、GBDT、K-means 等模型；深度学习模型比如 CNN、RNN、LSTM、 Seq2Seq、FastText、TextCNN 等。这些模型在后续的分类、聚类、神经序列、情感分析等示例中都会用到。
在模型训练时需要注意的几个点：
1、注意过拟合、欠拟合问题，不断提高模型的泛化能力。
2、对于神经网络，注意梯度消失和梯度爆炸问题。
6、评价指标 
训练好的模型，上线之前要对模型进行必要的评估，目的让模型对语料具备较好的泛化能力。具体有以下这些指标可以参考。
错误率、精度、准确率、精确度、召回率、F1 衡量。
错误率：是分类错误的样本数占样本总数的比例。
精度：是分类正确的样本数占样本总数的比例。
准确率：是针对我们预测结果而言的，它表示的是预测为正的样例中有多少是真正的正样例。
精确度：是分类正确的样本数占样本总数的比例。
召回率：是针对我们原来的样本而言的，它表示的是样本中的正例有多少被预测正确。
F1 衡量：表达出对查准率/查全率的不同偏好。
7、模型上线应用
模型线上应用，线下训练模型，然后将模型做线上部署，发布成接口服务以供业务系统使用。
【 问题：现在企业怎么做用户画像分析并应用的。】
1、

2、http://www.woshipm.com/pd/174984.htm
【 20190210 每日一问『某企业面试题』现在有一个5岁的小女孩，请你和她解释一下什么是机器学习和深度学习？】
1、机器学习：
形象化定义：
你想要个洋娃娃，圣诞老公公听到了世界各地孩子们的愿望。但是他今年只想送出一份礼物，于是他回看了过去一年所有孩子的表现，发现你表现的最好。于是在圣诞夜就把一个洋娃娃放到了你的袜子里；
形式化定义：
（1）机器学习其实就是你现在的学习，就是从有限的题目例子中，找出问题和答案之间规律的一个过程，这个规律在你的学习中叫做“知识”，在机器学习中叫做“模型”，模型描述了问题与答案之间的关系。
（2） 而当你学到了知识后，会有平时的测验模考来检验你是否掌握了知识，测验模考的题目和答案就是训练集，即你用你所认为学到的知识(模型)来预测你没见过的问题的答案，如果答对了，那么你总结的知识就是对的，否则重新学习修正，学习问题与答案之间关系的过程就叫做训练train；
（3）直到你有一个较好的总结后，最后将你学到的知识应用于考试，考试中的题目和答案就是测试集(test),考试中你使用你已有的知识解决问题的过程就叫做预测(predict)，预测完后，拿考试标准答案和你做的答案对比，对比的过程就是衡量你模型好坏的过程，就是模型评估；
简化式定义：
简言之，机器学习也可以表示为，我们只能从有限例子中来找到输入和输出的关系，进而学习出能够预测从未见过的情况的模型。
2、深度学习：
你想要个洋娃娃，是因为你喜欢洋娃娃身上的衣服。但圣诞老公公那里信号不好没有听到你的愿望。不过他通过回看世界各地孩子的表现发现你是过去一年的表现的最好的孩子，而且他还发现你最喜欢洋娃娃了，还总是梦想着能像他们一样漂亮。于是在圣诞夜的晚上他不仅把一个可爱的洋娃娃放到了你的袜子里，还送给你了一件和洋娃娃一模一样的衣服。
3、对比记忆：
不妨把
【机器学习】比【唐诗】，
【深度学习】比【宋词】。
我们都知道，诗词只是一种载体，它们要表达的情感都是一样的：这就好比两种AI学习，路径不同，解决目标是一样的；表面上，唐宋交迹，诗承词继，但实际它们在两个时代都有出现，只是在各自的时代有各自的繁盛期：两种AI学习也是这样的，不存在机器学习被取缔的情况；词比诗具有更加自由的形式，因而继承了诗的衣钵：深度学习比起机器学习，更能适应复杂的场景，因而现在大火。
【 20190209 每日一问 机器学习算法面试系列：什么是逻辑回归算法，它的优缺点是什么？】
1、逻辑回归
（1）逻辑回归就是这样的一个过程：面对一个回归或者分类问题，建立代价函数，然后通过优化方法迭代求解出最优的模型参数，然后测试验证我们这个求解的模型的好坏；
（2）Logistic回归虽然名字里带“回归”，但是它实际上是一种分类方法，主要用于两分类问题（即输出只有两种，分别代表两个类别）；
（3）回归模型中，y是一个定性变量，比如y=0或1，logistic方法主要应用于研究某些事件发生的概率。
2、优缺点
（1）优点：
速度快，适合二分类问题；
简单易于理解，直接看到各个特征的权重；
能容易地更新模型吸收新的数据
（2）缺点：
对数据和场景的适应能力有局限性，不如决策树算法适应性那么强；
3、参考🔗
https://mp.weixin.qq.com/s/mBvM_nQvgqvCz2qD2F0ruw
https://blog.csdn.net/asd2479745295/article/details/83065330?from=groupmessage&isappinstalled=0
【 20190207 每日一问机器学习算法面试系列：什么是kNN算法，它的优缺点是什么？】
1、kNN
（1）kNN是一种有监督的分类和回归算法。对于分类问题而言，其主要思想是通过新样本的k个最近邻的训练样本的类别，通过多数表决等方式实现类别预测。具体过程为：首先，根据给定的距离度量，在训练集T中找出与x最近邻的k个点；然后在这k个点的类别，根据分类决策规则（如多数表决）决定x的类别；
（2）k近邻算法，又称为懒惰算法。如果一个样本在特征空间中的k个最相似的样本中的大多数属于某一个类别，那么该样本也是这一类别。有点是无需训练，适合分类。缺点是计算量较大；
（3）k近邻。通过测量不同特征值之间的距离分类。某样本在特征空间中的K个最相似（最近邻）样本中的大多数属于哪类，该样本也属于该类。 算法简单，可用于非线性分类，时间复杂度为O(n)。但计算量大，可能遇到样本不平衡问题；
（4）kNN算法不仅可以用于分类，还可以用于“回归”。通过找出一个样本的k个最近邻居，将这些邻居的属性的平均值赋给该样本，就可以得到该样本的属性。更有用的方法是将不同距离的邻居对该样本产生的影响给予不同的权值(weight)，如权值与距离成反比
2、优缺点
（1）优点：
思想简单，理论成熟，既可以用来做分类也可以用来做“回归”； 
可用于非线性分类； 
训练时间复杂度为O(n)； 
准确度高，对数据没有假设，对噪声数据不敏感；
（2）主要优点：
理论成熟，思想简单，既可以用来做分类又可以做回归；
可以用于非线性分类；
训练时间复杂度比支持向量机之类的算法低；
和朴素贝叶斯之类的算法比，对数据没有假设，准确度高，对异常点不敏感；
由于kNN方法主要靠周围有限的邻近的样本，而不是靠判别类域的方法来确定所属的类别，因此对于类域的交叉或重叠较多的待分类样本集来说，kNN方法较其他方法更为适合；
该算法比较适用于样本容量比较大的类域的自动分类，而那些样本容量比较小的类域采用这种算法比较容易产生误分类情况。
（2）缺点：
计算量大； 
样本不平衡问题（即有些类别的样本数量很多，而其它样本的数量很少）； 
预测结果不具有可解释性；
维数灾难；
计算量大，尤其是特征数非常多的时候；
样本不平衡的时候，对稀有类别的预测准确率低；
KD树，球树之类的模型建立需要大量的内存；
是懒惰算法，基本上不学习，导致预测时速度比起逻辑回归之类的算法慢；
相比决策树模型，kNN模型的可解释性不强。
3、拓展：
（1）k值设定为多大？
k太小，分类结果易受噪声点影响；
k太大，近邻中又可能包含太多的其它类别的点。（对距离加权，可以降低k值设定的影响）
（2）k值通常是采用交叉检验来确定（以k=1为基准）经验规则：k一般低于训练样本数的平方根；
（3）类别如何判定最合适？
投票法没有考虑近邻的距离的远近，距离更近的近邻也许更应该决定最终的分类，所以加权投票法更恰当一些；
（4）如何选择合适的距离衡量？
高维度对距离衡量的影响：众所周知当变量数越多，欧式距离的区分能力就越差；
变量值域对距离的影响：值域越大的变量常常会在距离计算中占据主导作用，因此应先对变量进行标准化。
（5）训练样本是否要一视同仁？
在训练集中，有些样本可能是更值得依赖的；
可以给不同的样本施加不同的权重，加强依赖样本的权重，降低不可信赖样本的影响；
（6）性能问题：
kNN是一种懒惰算法，平时不好好学习，考试（对测试样本分类）时才临阵磨枪（临时去找k个近邻）；
懒惰的后果：构造模型很简单，但在对测试样本分类地的系统开销大，因为要扫描全部训练样本并计算距离；
已经有一些方法提高计算的效率，例如压缩训练样本量等；
（7）能否大幅减少训练样本量，同时又保持分类精度？
浓缩技术(condensing)
编辑技术(editing)
4、代码实现及理论解释🔗
https://blog.csdn.net/asd2479745295/article/details/82846551
https://blog.csdn.net/jmydream/article/details/8644004?from=message&isappinstalled=0

【 20190206 每日一问 数据分析师在企业中的价值是什么？优秀的数据分析应该具备哪些技能和特质？———某互联网企业笔试题 】


1、价值：
（1）根据当前数据，对比历史数据，结合市场规律对具体业务问题进行纠正，指导以及预测；
2、技能和特质：
（1）普通企业基本excle就能完成90%的数据分析工作，更多的是需要对业务的精通；
（2）互联网企业数据库操作能力是基本，R或者Python必会一项，但一般以Python居多，要求更高一点的都需要具备一定的数据挖掘能力；
（3）会使用各种工具对数据清洗、整理，熟悉一些编程技巧，对数据进行可视化，对业务有一定了解，能基于数据提出有力的观点结论；
（4）应具备统计学，计量经济学，时序分析，行为金融学等技能；
（5）掌握必要的编程能力（技巧）
找个简单的案例，模仿着，就算代码抄也要亲自打，然后在此基础上自己发散思维扩展功能，为了实现功能就会逼迫自己去查文档、手册，每天都搞个案例再拓展功能，不出2月自然就熟悉了，最关键的是要有毅力；
初期先看看教程把基本语法学会；
我当时自学数据结构是跟着网课来的，中国大学慕课网 里的 浙大数据结构，讲得十分细致，同时还给出了PAT的题目练习。我基本上从那里开始入的门；
至于对编程开始有感觉，视野开阔起来。想实现什么就能自己找资料摸索，是在完成真正意义上的一个小项目之后了。做小项目的时候，经常要各种搜索，能力大概是在那个时候提升的。
3、L1-norm和L2-norm的区别和作用
（1）区别
范数：指的是向量的长度；
L1范数是指向量中各个向量元素的绝对值之和；
L2范数是指各个各个向量元素的平方和再开方。
（2）作用
L1范数相当于L0范数，使特征更多成为0，即特征稀疏化（L0范数很难求优化，所以用的L1范数），方便特征提取；
L2范数可以防止过拟合，提升模型的泛化能力。

L1-norm

L2-norm
4、什么是模型过拟合，请列举一下模型过拟合的原因及解决办法？
（1）由噪声导致的过拟合：噪声具有一定的随机性与欺骗性，如果把噪声作为有效信息的话，将会导致过拟合；
（2）缺乏代表性样本导致的过拟合：
训练数据集不能很好的反映整体分布可能会导致过拟合；
训练数据集较小，但模型过度细化会导致过拟合；
（3）从定量角度来讲，过拟合常常表现为模型的“方差variance”过大，而欠拟合则表现为模型的“偏差bias”过大；
（4）降低过拟合的方法：
增大训练集，更多的样本可以让模型学到更多有效的特征；
正则化，将权重的大小加入损失函数中，避免权值过大引起的过拟合，比如L1/L2正则；
降低模型复杂度，比如 dropout，决策树剪枝等；
bagging 方法，bagging 的思路是对模型的结果取平均。取平均后模型的方差降低，为避免模型之间的相关性过大，像随机森林采取了对特征随机选择的方法，但是boosting并不能显著降低方差，因为各个弱分类器间是强相关的。
5、特征挑选（选择）的方法有哪些？
通常来说，从两个方面考虑来选择特征：
（1）特征是否发散：如果一个特征不发散，例如方差接近于0，也就是说样本在这个特征上基本上没有差异，这个特征对于样本的区分并没有什么用；
（2）特征与目标的相关性：这点比较显见，与目标相关性高的特征，应当优选选择。除方差法外，其他方法均从相关性考虑。
根据特征选择的形式:
（1）Filter：过滤法，按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征。通过该方法选出来的特征与具体的预测模型没有关系，因此具有更好的泛化能力；
（2）Wrapper：包装法，根据目标函数（通常是预测效果评分），每次选择若干特征，或者排除若干特征。围绕一定的预测模型，预测模型的估计误差一定程度上反映了特征的有用性；
（3）Embedded：集成法，先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。

参考链接
http://www.cnblogs.com/jasonfreak/p/5448385.html
6、机器学习中为什么要经常对数据做归一化处理？一般适用于什么情形
（1）

（2）对于不同的特征向量，比如年龄、购买量、购买额，在数值的量纲上相差十倍或者百千倍。如果不归一化处理，就不容易进行比较、求距离，模型参数和正确度、精确度就会受到影响，比如：计算样本距离时，如果特征向量取值范围相差很大，如果不进行归一化处理，则值范围更大的特征向量对距离的影响更大，而实际情况是，取值范围更小的特征向量对距离影响更大，这样的话，精度就会受到影响；
（3）

（4）归一化和标准化的区别和联系
标准化：在机器学习中，我们可能要处理不同种类的资料，例如，音讯和图片上的像素值，这些资料可能是高维度的，资料标准化后会使每个特征中的数值平均变为0(将每个特征的值都减掉原始资料中该特征的平均)、标准差变为1，这个方法被广泛的使用在许多机器学习算法中(例如：支持向量机、逻辑回归和类神经网络)；
Z-score标准化（标准差标准化 / 零均值标准化）x’ = (x - μ)／σ
归一化 Min-Max Normalization：x’ = (x - X_min) / (X_max - X_min)
归一化是将样本的特征值转换到同一量纲下把数据映射到[0,1]或者[a,b]区间内，仅由变量的极值决定，因此区间放缩法是归一化的一种；
标准化是依照特征矩阵的列处理数据，其通过求z-score的方法，转换为标准正态分布，和整体样本分布相关，每个样本点都能对标准化产生影响；
归一区间，会改变数据的原始距离，分布，信息；标准化一般不会。
联系：
它们的相同点在于都能取消由于量纲不同引起的误差；
都是一种线性变换，都是对向量X按照比例压缩再进行平移；
使用情形：什么时候用归一化？什么时候用标准化？
如果对输出结果范围有要求，用归一化；
如果数据较为稳定，不存在极端的最大最小值，用归一化；
如果数据存在异常值和较多噪音，用标准化，可以间接通过中心化避免异常值和极端值的影响；
哪些模型必须归一化/标准化？
SVM
kNN 
神经网络
PCA
参考链接：
https://blog.csdn.net/ybdesire/article/details/56027408
https://www.zhihu.com/question/20455227/answer/370658612
7、拓展🔗
https://mp.weixin.qq.com/s/Do2LCjo0bSBudp-Syj634Q
总结：数据驱动、发现问题、解决问题
